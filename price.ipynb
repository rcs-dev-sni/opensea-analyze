{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698d9cda-bfcd-4564-8e93-5dc3e3b0ee68",
   "metadata": {},
   "source": [
    "## Change these if not running over BAYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84032188-9c68-4a4e-a208-242bd32322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = 'boredapeyachtclub'\n",
    "COLLECTION_SIZE = 10000\n",
    "\n",
    "collection_file = f\"{COLLECTION}.ndjson\"\n",
    "traits_file = f\"{COLLECTION}_traits.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ea5ae-bb99-4378-a2c7-fd230bde3ab4",
   "metadata": {},
   "source": [
    "# Load Collection Data (only needs to run once per collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe1418-e34c-4409-9850-4a61b41ee8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "MAX_RES = 50\n",
    "\n",
    "# fetch a single page of results from opensea, return JSON\n",
    "def fetch_page(offset):\n",
    "    p = {\n",
    "        'order_direction': 'asc',\n",
    "        'offset': offset,\n",
    "        'limit': MAX_RES,\n",
    "        'collection': COLLECTION,\n",
    "    }\n",
    "    r = requests.get('https://api.opensea.io/api/v1/assets', params=p)\n",
    "    return r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e7d1a-bb9b-45a8-88bd-89e42f33edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_offset = 0\n",
    "end_offset = COLLECTION_SIZE\n",
    "# using append to make retries easier\n",
    "with open(collection_file, 'a') as of:\n",
    "    while cur_offset < end_offset:\n",
    "        res = fetch_page(cur_offset)\n",
    "        for a in res['assets']:\n",
    "            of.write(json.dumps(a))\n",
    "            of.write('\\n')\n",
    "        time.sleep(0.25)\n",
    "        cur_offset += MAX_RES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d1b42-dfc9-434c-a266-bac9a3e0908b",
   "metadata": {},
   "source": [
    "# Get Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7c5a8-07cf-4414-a4ac-ea8179e1df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def trait_name(trait_json):\n",
    "    return f\"{trait_json['trait_type']}_{trait_json['value'].replace(' ', '-')}\"\n",
    "\n",
    "traits = {}\n",
    "\n",
    "with open(collection_file, 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        j = json.loads(l)\n",
    "        for t in j['traits']:\n",
    "            traits[trait_name(t)] = t['trait_count']\n",
    "    with open(traits_file, 'w') as of:\n",
    "        for t in sorted(traits):\n",
    "            of.write(f\"{t}\\t{traits[t]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751980b6-aa43-418e-84ff-7dd6c4bb3a33",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515e8b2-ee0e-4a41-b062-b9c6d75d7bbc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9fc09-d1c5-46ec-947c-1e74d38396a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb884a0d-76b0-48f9-aa5e-4406dc72be61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trait_name(trait_json):\n",
    "    return f\"{trait_json['trait_type']}_{trait_json['value'].replace(' ', '-')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137f3ff-8509-434e-9278-709874b7ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load traits and make helper dicts\n",
    "\n",
    "trait_to_count = {}\n",
    "trait_to_idx = {}\n",
    "idx_to_trait = {}\n",
    "\n",
    "with open(traits_file, 'r') as f:\n",
    "    for idx, l in enumerate(f.readlines()):\n",
    "        trait, count = l.split()\n",
    "        trait_to_count[trait] = count\n",
    "        trait_to_idx[trait] = idx\n",
    "        idx_to_trait[idx] = trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68d79d-ff96-4805-a2a3-d7ac83ba4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_trait_features(in_json):\n",
    "    \"\"\"Take asset json from OpenSea, extract traits into a feature vector.\"\"\"\n",
    "    features = [0] * len(trait_to_idx)\n",
    "    for t in in_json['traits']:\n",
    "        trait = trait_name(t)\n",
    "        features[trait_to_idx[trait]] = 1\n",
    "    return features\n",
    "\n",
    "def json_to_sell_order_price(in_json):\n",
    "    \"\"\"Prices are based on the current sell orders, which probably can be improved. Denominated in ETH. (Double check these, OpenSea API is a bit weird here.)\"\"\"\n",
    "    if in_json['sell_orders'] is None:\n",
    "        return None\n",
    "    so = in_json['sell_orders'][0]\n",
    "    if so['payment_token_contract']['symbol'] not in ['ETH']:\n",
    "        return None # need to understand better, OpenSea seems to be doing weird stuff w/USDC sales.\n",
    "    eth_price = float(so['payment_token_contract']['eth_price'])\n",
    "    return (float(so['current_price']) / 1000000000000000000.0) * eth_price\n",
    "\n",
    "def convert_ts_string(ts_str):\n",
    "    \"\"\"Strips fractional seconds before conversion.\"\"\"\n",
    "    return datetime.strptime(ts_str.split('.')[0], '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "def json_to_last_sale_price(in_json, in_last_days=30):\n",
    "    \"\"\"Prices are based on prior sales. Denominated in ETH.\"\"\"\n",
    "    if in_json['last_sale'] is None:\n",
    "        return None\n",
    "    s = in_json['last_sale']\n",
    "    sale_ts = convert_ts_string(s['event_timestamp'])\n",
    "    cutoff = datetime.now() - timedelta(days=in_last_days)\n",
    "    if sale_ts < cutoff:\n",
    "        return None\n",
    "    if s['payment_token']['symbol'] not in ['ETH', 'WETH']:\n",
    "        return None # need to understand better, OpenSea seems to be doing weird stuff w/USDC sales.\n",
    "    eth_price = float(s['payment_token']['eth_price'])\n",
    "    return (float(s['total_price']) / 1000000000000000000.0) * eth_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57729697-1a7f-497d-883c-db2b30a2109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_weights(model, unseen_traits):\n",
    "    \"\"\"sorted weights from sklearn model\"\"\"\n",
    "    trait_weights = [(t, model.coef_[trait_to_idx[t]]) for t in trait_to_idx if t not in unseen_traits]\n",
    "    trait_weights.sort(key=lambda x: x[1])\n",
    "    return trait_weights\n",
    "\n",
    "def price_delta(in_model, asset):\n",
    "    \"\"\"Gives model prediction - actual price (positive is 'undervalued', negative is 'overvalued' assuming the model is correct (it's not))\"\"\"\n",
    "    if asset[1] is None:\n",
    "        return None\n",
    "    return in_model.predict([asset[0]])[0] - asset[1]\n",
    "\n",
    "def price_premium_percentage(in_model, asset):\n",
    "    \"\"\"Gives model prediction / actual price (> 1 is 'undervalued', < 1 is 'overvalued' assuming the model is correct (it's not))\"\"\"\n",
    "    if asset[1] is None:\n",
    "        return None\n",
    "    return in_model.predict([asset[0]])[0] / asset[1]\n",
    "\n",
    "def feature_vector_to_traits(fv):\n",
    "    return [idx_to_trait[idx] for idx in range(len(fv)) if fv[idx]]            \n",
    "\n",
    "def good_asset_price(price):\n",
    "    return price is not None and price > 10\n",
    "\n",
    "def explained_score(eval_model, asset):\n",
    "    print(f\"Average price: {eval_model.intercept_}\")\n",
    "    for idx, v in enumerate(asset[0]):\n",
    "        if v:\n",
    "            print(f\"\\t{idx_to_trait[idx]}\\t{eval_model.coef_[idx]}\")\n",
    "    print(f\"Total: {eval_model.predict([asset[0]])[0]}\")\n",
    "\n",
    "def eval_model(eval_model, X, Y):\n",
    "    print(f\"Score: {eval_model.score(X,Y)}\")\n",
    "    print(f\"Num Features: {len(Y)}\")\n",
    "    deltas = [(k, price_delta(eval_model, assets[k])) for k in assets if good_asset_price(assets[k][1])]\n",
    "    deltas.sort(key=lambda x: x[1])\n",
    "    print(f\"Overvalued sales (absolute): {deltas[:3]}\")\n",
    "    print(f\"Undervalued sales (absolute): {deltas[-3:]}\")\n",
    "    deltas = [(k, price_premium_percentage(eval_model, assets[k])) for k in assets if good_asset_price(assets[k][1])]\n",
    "    deltas.sort(key=lambda x: x[1])\n",
    "    print(f\"Overvalued sales (relative): {deltas[:3]}\")\n",
    "    print(f\"Undervalued sales (relative): {deltas[-3:]}\")\n",
    "    # correlation between trait count and trait coefficient (i.e. rarity impact)\n",
    "    trait_counts = [float(trait_to_count[idx_to_trait[idx]]) for idx in range(len(trait_to_count))]\n",
    "    print(f\"Trait count / price impact correlation: {pearsonr(eval_model.coef_, trait_counts)}\")\n",
    "    unseen_traits = [t for t in trait_to_idx if trait_to_idx[t] not in seen_feature_idx]\n",
    "    unseen_traits.sort()\n",
    "    print(\"\\nUnseen traits:\")\n",
    "    for t in unseen_traits:\n",
    "        print(f\"\\t{t}\")\n",
    "    print(\"\\nTrait weights:\")\n",
    "    for tw in trait_weights(eval_model, unseen_traits):\n",
    "        if tw[1]:\n",
    "            print(f\"\\t{tw[0]}\\t{tw[1]}\")\n",
    "            \n",
    "def find_deals(model, assets, top_n=5):\n",
    "    def all_traits_seen(asset):\n",
    "        for idx, v in enumerate(asset[0]):\n",
    "            if v and (idx not in seen_feature_idx):\n",
    "                return False\n",
    "        return True\n",
    "    sale_deltas = [(aid, model.predict([assets[aid][0]])[0], assets[aid][2]) for aid in assets if assets[aid][2] and all_traits_seen(assets[aid])]\n",
    "    deals = list(filter(lambda x: x[1] - x[2] > 0, sale_deltas))\n",
    "    deals.sort(key=lambda x: x[2] - x[1])\n",
    "    print(f\"Deals (total {len(deals)}/{len(sale_deltas)})\\t(id, predicted price, sale price, delta)\")\n",
    "    for x in deals[:top_n]:\n",
    "        print(f\"\\t{x[0]}\\t{x[1]}\\t{x[2]}\\t{x[1]-x[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525afa1-0101-42e4-955e-038f7f13aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = {} # dict from asset id to (features, last sale price, current list price)\n",
    "\n",
    "with open(collection_file, 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        json_asset = json.loads(l)\n",
    "        assets[json_asset['token_id']] = (json_to_trait_features(json_asset), json_to_last_sale_price(json_asset, in_last_days=30), json_to_sell_order_price(json_asset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ea3c3-a5d5-4314-b9a4-e248b107774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "seen_feature_idx = set()\n",
    "\n",
    "for v in assets.values():\n",
    "    if good_asset_price(v[1]):\n",
    "        X.append(v[0])\n",
    "        Y.append(v[1])\n",
    "        for i, v in enumerate(v[0]):\n",
    "            if v:\n",
    "                seen_feature_idx.add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582aa5d-2125-45c9-87b1-b969b376b312",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f77bc7-16f3-4493-93bd-984d49454e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False).fit(X, Y)\n",
    "eval_model(model, X, Y)\n",
    "find_deals(model, assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17793d-1836-4e42-8513-7be707635f19",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a3f30-8c65-4d0e-bf81-3495bf2c9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = Lasso().fit(X, Y)\n",
    "eval_model(lmodel, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218ec1d-6fdc-4dbf-a7d4-05f46a4434ca",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab539f1d-9a98-4cbf-9c66-b8776268de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmodel = ElasticNet().fit(X, Y)\n",
    "eval_model(elmodel, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b8a75-5bf4-4cf2-9009-f5f88b9da271",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96e372-ee37-4b5e-b8d2-341b30014bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmodel = Ridge().fit(X,Y)\n",
    "eval_model(rmodel, X, Y)\n",
    "find_deals(model, assets, top_n=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
